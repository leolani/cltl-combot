# Virtual Leolani

This repo has been created for human-robot interaction with coversation.

## About the Project

At [CLTL](http://www.cltl.nl/) we have an existing [Leolani platform](https://github.com/cltl-leolani/pepper), which we still develop and maintain to this date. However it has the following limitations:

* It's based on a physical robot, which is are hard to prototpye.
* It uses the Softbank SDK python2 library (it's the only option to be compatible with Softbank)
* Pepper can't make facial expressions.

This repo will overcome the limitations and foster the communications between humans and robots.

## Work in Progress
Refer to [`overall_architecture.md`](https://github.com/cltl-leolani/virtual-leolani/blob/main/overall_architecture.md).


<!-- ## Getting Started

This is an example of how you may give instructions on setting up your project locally.
To get a local copy up and running follow these simple example steps.

### Prerequisites

```
TBD
```

### Installation

```
TBD
```


## Usage

TBD -->


## Contributing

Contributions are what make the open source community such an amazing place to be learn, inspire, and create. Any contributions you make are **greatly appreciated**.

1. Fork the Project
2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)
3. Commit your Changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the Branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request


<!-- LICENSE -->
## License

Distributed under the MIT License. See [`LICENSE`](https://github.com/cltl-leolani/virtual-leolani/blob/main/LICENSE) for more information.



<!-- CONTACT -->
## Authors

* [Taewoon Kim](https://tae898.github.io/)
